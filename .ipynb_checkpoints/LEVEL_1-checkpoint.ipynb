{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Tutorial - Level 1\n",
    "\n",
    "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we import the packages we are going to need to do the analysis\n"
     ]
    }
   ],
   "source": [
    "print(\"Here we import the packages we are going to need to do the analysis\")\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been imported as df\n",
      "Let's have a look at the first 10 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>570300767074181121</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>570295459631263746</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>570289724453216256</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>570289584061480960</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>570285904809598977</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>570277724385734656</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica So excited for my first cross c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>570276917301137409</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>570270684619923457</td>\n",
       "      <td>positive</td>\n",
       "      <td>I ‚ù§Ô∏è flying @VirginAmerica. üëç ‚ò∫Ô∏è</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            tweet_id airline_sentiment  \\\n",
       "0           3  570301031407624196          negative   \n",
       "1           4  570300817074462722          negative   \n",
       "2           5  570300767074181121          negative   \n",
       "3           9  570295459631263746          positive   \n",
       "4          11  570289724453216256          positive   \n",
       "5          12  570289584061480960          positive   \n",
       "6          14  570285904809598977          positive   \n",
       "7          16  570277724385734656          positive   \n",
       "8          17  570276917301137409          negative   \n",
       "9          18  570270684619923457          positive   \n",
       "\n",
       "                                                text  \n",
       "0  @VirginAmerica it's really aggressive to blast...  \n",
       "1  @VirginAmerica and it's a really big bad thing...  \n",
       "2  @VirginAmerica seriously would pay $30 a fligh...  \n",
       "3  @VirginAmerica it was amazing, and arrived an ...  \n",
       "4  @VirginAmerica I &lt;3 pretty graphics. so muc...  \n",
       "5  @VirginAmerica This is such a great deal! Alre...  \n",
       "6                             @VirginAmerica Thanks!  \n",
       "7  @VirginAmerica So excited for my first cross c...  \n",
       "8  @VirginAmerica  I flew from NYC to SFO last we...  \n",
       "9                   I ‚ù§Ô∏è flying @VirginAmerica. üëç ‚ò∫Ô∏è  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This command imports the dataset\n",
    "df = pd.read_csv(\"dataset_sentiment/Tweets_level_1.csv\")\n",
    "\n",
    "print(\"Dataset has been imported as df\")\n",
    "\n",
    "print(\"Let's have a look at the first 10 rows\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We see that each row is a unique Tweet and each column gives us some specific information about the tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 9134 rows and 4 columns.\n",
      "Which also means we have 9134 Tweets and 4 pieces of info about each tweet.\n"
     ]
    }
   ],
   "source": [
    "#The command .shape gets two numbers: the number of rows and the number of columns\n",
    "a,b = df.shape\n",
    "print(\"The dataframe has \" + str(a) +\" rows and \" + str(b) + \" columns.\")\n",
    "\n",
    "print(\"Which also means we have \" + str(a) +\" Tweets and \" + str(b) + \" pieces of info about each tweet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#The command .columns gets the columns of the dataset\n",
    "\n",
    "columns = df.columns\n",
    "\n",
    "print(\"The columns of the dataset are: \\n\")\n",
    "for i,k in enumerate(columns): print(i+1, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's each column for?\n",
    "\n",
    "We can go to the page where we got the dataset from, and we will find a description of each column: https://www.kaggle.com/crowdflower/twitter-airline-sentiment\n",
    "\n",
    "1. **tweet_id** The ID of the tweet\n",
    "2. **airline_sentiment** The sentiment of the tweet\n",
    "3. **text** The text of the Tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Let's look at the Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 9134 Tweets.\n"
     ]
    }
   ],
   "source": [
    "n_tweets = len(df['text'])\n",
    "print(\"There is a total of \" + str(n_tweets) + \" Tweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1: @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse (negative)\n",
      "\n",
      "Tweet 2: @VirginAmerica and it's a really big bad thing about it (negative)\n",
      "\n",
      "Tweet 3: @VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\n",
      "it's really the only bad thing about flying VA (negative)\n",
      "\n",
      "Tweet 4: @VirginAmerica it was amazing, and arrived an hour early. You're too good to me. (positive)\n",
      "\n",
      "Tweet 5: @VirginAmerica I &lt;3 pretty graphics. so much better than minimal iconography. :D (positive)\n",
      "\n",
      "Tweet 6: @VirginAmerica This is such a great deal! Already thinking about my 2nd trip to @Australia &amp; I haven't even gone on my 1st trip yet! ;p (positive)\n",
      "\n",
      "Tweet 7: @VirginAmerica Thanks! (positive)\n",
      "\n",
      "Tweet 8: @VirginAmerica So excited for my first cross country flight LAX to MCO I've heard nothing but great things about Virgin America. #29DaysToGo (positive)\n",
      "\n",
      "Tweet 9: @VirginAmerica  I flew from NYC to SFO last week and couldn't fully sit in my seat due to two large gentleman on either side of me. HELP! (negative)\n",
      "\n",
      "Tweet 10: I ‚ù§Ô∏è flying @VirginAmerica. üëç ‚ò∫Ô∏è (positive)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,k in enumerate(df['text'][0:10]): print(\"Tweet \" + str(i+1) + \":\",  k, \"(\" + str(df['airline_sentiment'].to_list()[i]) + \")\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start the cleaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "tweets = df['text'].to_list()\n",
    "\n",
    "def basic_cleaning(tweet):\n",
    "\n",
    "    #This makes text lowercase\n",
    "    tweet = tweet.lower()\n",
    "    #This removes hashtag\n",
    "    tweet = tweet.replace(\"#\",\"\")\n",
    "    #This removes any sequence of characters that starts with \"@\" i.e. usernames\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    #Remove any HTML special symbols such as &amp;\n",
    "    tweet = re.sub('(?:\\s)&[^, ]*', '', tweet)\n",
    "\n",
    "    #We remove digits\n",
    "    tweet = ''.join([i for i in tweet if not i.isdigit()])\n",
    "    \n",
    "    #We remove digits\n",
    "    tweet = ''.join([i for i in tweet if not i.isdigit()])\n",
    "    \n",
    "    #And now we can finally remove punctuation\n",
    "    for c in string.punctuation:\n",
    "        tweet = tweet.replace(c,\"\")\n",
    "        \n",
    "    tweet = emoji.demojize(tweet)\n",
    "\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#You apply the basic_cleaning function to all the tweets\n",
    "tweets = [basic_cleaning(tweet) for tweet in tweets]\n",
    "\n",
    "#And display the results\n",
    "for i,k in enumerate(tweets[0:10]): print(\"Tweet \" + str(i+1) + \":\",  k, \"(\" + str(df['airline_sentiment'].to_list()[i]) + \")\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do we do with emojis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#the library that is gonna do the translation of complex emojis for us\n",
    "import emoji\n",
    "\n",
    "#Translating simple emojis\n",
    "def translating_emojis(tweet):\n",
    "\n",
    "    #Dealing with happy emojis\n",
    "    tweet = tweet.replace(\":d\",\"happy_face\")\n",
    "    tweet = tweet.replace(\":)\",\"happy_face\")\n",
    "    tweet = tweet.replace(\";d\",\"happy_face\")\n",
    "    tweet = tweet.replace(\";)\",\"happy_face\")\n",
    "    tweet = tweet.replace(\";p\",\"happy_face\")\n",
    "    tweet = tweet.replace(\":p\",\"happy_face\")\n",
    "\n",
    "    #Dealing with sad emojis\n",
    "    tweet = tweet.replace(\":(\",\"unhappy_face\")\n",
    "    tweet = tweet.replace(\":/\",\"unhappy_face\")\n",
    "\n",
    "\n",
    "    #we use the emoji library for dealing with complex emojis\n",
    "    tweet = emoji.demojize(tweet)\n",
    "\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Apply emoji translator to all tweets\n",
    "tweets = [translating_emojis(tweet) for tweet in tweets]\n",
    "\n",
    "for i,k in enumerate(tweets[0:10]): print(i+1,  k, \"(\" + str(df['airline_sentiment'].to_list()[i]) + \")\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting a String of Text into Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenise_tweets(tweet):\n",
    "\n",
    "    tweet = tweet.split()\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Apply tokeniserr to all tweets\n",
    "tweets = [tokenise_tweets(tweet) for tweet in tweets]\n",
    "\n",
    "for i,k in enumerate(tweets[0:10]): print(i+1,  k, \"(\" + str(df['airline_sentiment'].to_list()[i]) + \")\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def advance_cleaning(tweet):\n",
    "\n",
    "    #Remove stopwords in list stopwords.words('english')\n",
    "    tweet = [word for word in tweet if not word in stopwords.words('english')]\n",
    "\n",
    "\n",
    "    #Lemmatizing verbs\n",
    "    tweet = [wnl.lemmatize(word, pos='v') for word in tweet]\n",
    "    #Lemmatizing nouns\n",
    "    tweet = [wnl.lemmatize(word, pos='n') for word in tweet]\n",
    "    #Lemmatizing adjectives\n",
    "    tweet = [wnl.lemmatize(word, pos='a') for word in tweet]\n",
    "    tweet = [wnl.lemmatize(word, pos='s') for word in tweet]\n",
    "    #Lemmatizing adverbs\n",
    "    tweet = [wnl.lemmatize(word, pos='r') for word in tweet]\n",
    "\n",
    "\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Apply advance cleaning to all tweets\n",
    "tweets = [advance_cleaning(tweet) for tweet in tweets]\n",
    "\n",
    "for i,k in enumerate(tweets[0:10]): print(i+1,  k, \"(\" + str(df['airline_sentiment'].to_list()[i]) + \")\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#We put the preprocessed tweets back to the dataset as a new column\n",
    "df['preprocessed_tweets'] = tweets\n",
    "\n",
    "#Our dataset now looks like this\n",
    "print(\"Our dataset now has a new column called preprocessed_tweets\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some visual exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "all_tweets = list(itertools.chain.from_iterable(df['preprocessed_tweets'].to_list()))\n",
    "\n",
    "\n",
    "positive_df = df[df['airline_sentiment'] == 'positive']\n",
    "negative_df = df[df['airline_sentiment'] == 'negative']\n",
    "\n",
    "positive_tweets = list(itertools.chain.from_iterable(positive_df['preprocessed_tweets'].to_list()))\n",
    "negative_tweets = list(itertools.chain.from_iterable(negative_df['preprocessed_tweets'].to_list()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list_of_lens = [len(a_list) for a_list in df['preprocessed_tweets'].to_list()]\n",
    "\n",
    "average = sum(list_of_lens) / len(list_of_lens)\n",
    "\n",
    "print(\"Average length of tweets\" , average, \"words\")\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(list_of_lens, density=False, bins=20)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel(\"Len of Tweets\")\n",
    "plt.title(\"Tweet Length\")\n",
    "fig.savefig(\"len_plots/tweet_lens.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab of positive tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Exploring positive tweets\")\n",
    "\n",
    "fdist = FreqDist(positive_tweets)\n",
    "\n",
    "print(\"Total number of words \", len(positive_tweets))\n",
    "print(\"Number of unique vocabulary items \", len(set(positive_tweets)))\n",
    "print(\"10 most common vocabulary items \", fdist.most_common(10))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "fdist.plot(50, cumulative=False)\n",
    "fig.suptitle('positive', fontsize=16)\n",
    "fig.savefig('freq_dist_plots/freqDistpositive.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab of negative Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Exploring negative tweets\")\n",
    "\n",
    "fdist = FreqDist(negative_tweets)\n",
    "\n",
    "print(\"Total number of words \", len(negative_tweets))\n",
    "print(\"Number of unique vocabulary items \", len(set(negative_tweets)))\n",
    "print(\"10 most common vocabulary items \", fdist.most_common(10))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "fdist.plot(50, cumulative=False)\n",
    "fig.suptitle('positive', fontsize=16)\n",
    "fig.savefig('freq_dist_plots/freqDistpositive.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tag import map_tag\n",
    "from collections import Counter\n",
    "\n",
    "tags = nltk.pos_tag(all_tweets)\n",
    "\n",
    "simplifiedTags = [(word, map_tag('en-ptb', 'universal', tag)) for word, tag in tags]\n",
    "\n",
    "counts = Counter(tag for word, tag in simplifiedTags)\n",
    "\n",
    "# Counter data, counter is your counter object\n",
    "keys = counts.keys()\n",
    "y_pos = np.arange(len(keys))\n",
    "# get the counts for each key, assuming the values are numerical\n",
    "frequency = [counts[k] for k in keys]\n",
    "\n",
    "\n",
    "plt.barh(y_pos, frequency, align='center', alpha=0.4)\n",
    "plt.yticks(y_pos, keys)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('POS tag')\n",
    "plt.title('Most common POS tags ')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lunchnlearn)",
   "language": "python",
   "name": "pycharm-d77c99da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
